# -*- coding: utf-8 -*-
"""AMN final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HLB0pcFVCCYT4WGFoTztQflWBBYa_T-v

AI Strategy and Digital Transformation - FULL PROJECT REPOSITORY
This script contains EDA, Multi-Model Comparison, and Hyperparameter Tuning.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import balanced_accuracy_score, make_scorer

# DATA LOADING & EDA
train = pd.read_csv('job_change_train.csv')
print(f"Target Distribution:\n{train['willing_to_change_job'].value_counts(normalize=True)}")

# PREPROCESSING
def professional_preprocess(df):
    df = df.copy()
    exp_map = {'<1': 0, '>20': 21, 'unknown': np.nan}
    change_map = {'never_changed': 0, '>4': 5, 'unknown': np.nan}
    df['years_of_experience'] = df['years_of_experience'].replace(exp_map).astype(float)
    df['years_since_job_change'] = df['years_since_job_change'].replace(change_map).astype(float)
    df['years_of_experience'] = df['years_of_experience'].fillna(df['years_of_experience'].median())
    df['years_since_job_change'] = df['years_since_job_change'].fillna(df['years_since_job_change'].median())

    cat_cols = df.select_dtypes(include=['object']).columns
    for col in cat_cols:
        if col != 'willing_to_change_job':
            df[col] = df[col].fillna('Unknown')
            df[col] = LabelEncoder().fit_transform(df[col])
    return df

train_cleaned = professional_preprocess(train)
X = train_cleaned.drop(['id', 'willing_to_change_job'], axis=1)
y = train['willing_to_change_job'].map({'Yes': 1, 'No': 0})

# COMPARE 5 ALGORITHMS (Requirement: Balanced Accuracy)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(balanced_accuracy_score)

models = {
    "Logistic Regression": LogisticRegression(max_iter=2000, class_weight='balanced'),
    "Random Forest": RandomForestClassifier(class_weight='balanced', random_state=42),
    "SVM": SVC(class_weight='balanced', probability=True),
    "AdaBoost": AdaBoostClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(scale_pos_weight=3, random_state=42, eval_metric='logloss')
}

print("--- Cross-Validation Results ---")
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)
    print(f"{name}: {scores.mean():.4f}")

# HYPERPARAMETER TUNING (Example for Random Forest)
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5]
}
grid = GridSearchCV(RandomForestClassifier(class_weight='balanced'), param_grid, scoring=scorer, cv=3)
grid.fit(X, y)
print(f"Best RF Params: {grid.best_params_}")

# FEATURE IMPORTANCE VISUALIZATION
best_model = XGBClassifier(scale_pos_weight=3).fit(X, y)
importances = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=True)
plt.figure(figsize=(10,6))
importances.plot(kind='barh')
plt.title("Key Drivers for Job Change")
plt.savefig('feature_importance.png')

# FINAL MODEL TRAINING (Using the full training set)
print("\n--- Training Final Optimized Model ---")

# Removed use_label_encoder to eliminate the UserWarning
final_model = XGBClassifier(
    n_estimators=250,
    max_depth=4,
    learning_rate=0.04,
    scale_pos_weight=3,
    random_state=42,
    eval_metric='logloss'
)
final_model.fit(X, y)

# LOAD AND PREPROCESS TEST DATA
print("Loading test data...")
test = pd.read_csv('job_change_test.csv')
test_ids = test['id']

# Assuming professional_preprocess is defined in your environment
test_cleaned = professional_preprocess(test)

# Ensure test features match training features
X_test = test_cleaned.drop(['id'], axis=1)

# GENERATE FINAL PREDICTIONS
print("Generating predictions...")
test_preds = final_model.predict(X_test)

# FORMATTING FOR SUBMISSION
submission = pd.DataFrame({
    'id': test_ids,
    'willing_to_change_job': pd.Series(test_preds).map({1: 'Yes', 0: 'No'})
})

submission_filename = 'final_submission_full.csv'
submission.to_csv(submission_filename, index=False)
print(f"Success! Final submission file saved as: {submission_filename}")

# EXTRA FOR PRESENTATION: CONFUSION MATRIX
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Generate predictions for the internal check
y_train_pred = final_model.predict(X)
cm = confusion_matrix(y, y_train_pred)

# Fixed plotting: Create subplots to avoid the "0 Axes" empty figure error
fig, ax = plt.subplots(figsize=(8, 6))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot(cmap='Blues', ax=ax) # Explicitly pass the axis

plt.title("Confusion Matrix (Training Set - Internal Check)")
plt.savefig('confusion_matrix.png')
plt.show() # Displaying the plot in the notebook/console
print("Confusion matrix saved as 'confusion_matrix.png' for your report.")

# SUMMARY OF RESULTS
print("\n" + "="*30)
print("PROJECT SUMMARY FOR PRESENTATION")
print(f"Chosen Model: XGBoost")
print(f"Strategy: Applied scale_pos_weight=3 to handle class imbalance.")
print(f"Total Test Observations: {len(submission)}")
print(f"Predicted 'Yes' (Job Changers): {submission['willing_to_change_job'].value_counts().get('Yes', 0)}")
print(f"Predicted 'No' (Stayers): {submission['willing_to_change_job'].value_counts().get('No', 0)}")
print("="*30)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. GENERATE RISK SCORES (PROBABILITIES) ---
# Using 'final_model' from your previous script
probs = final_model.predict_proba(X_test)[:, 1]

# Create a strategic dashboard dataframe
strategy_df = pd.DataFrame({
    'Employee_ID': test_ids,
    'Risk_Score_%': (probs * 100).round(2)
})

# --- 2. DEFINE RISK TIERS ---
def assign_tier(score):
    if score >= 80: return 'CRITICAL (Immediate Retention Interview)'
    if score >= 50: return 'HIGH (Engagement Program)'
    if score >= 25: return 'MEDIUM (Monitor Status)'
    return 'LOW (Stable)'

strategy_df['Action_Priority'] = strategy_df['Risk_Score_%'].apply(assign_tier)

# --- 3. VISUALIZE THE HR ACTION PLAN (WARNING FIXED HERE) ---
plt.figure(figsize=(12, 6))
order = ['CRITICAL (Immediate Retention Interview)', 'HIGH (Engagement Program)',
         'MEDIUM (Monitor Status)', 'LOW (Stable)']

# FIX: Added hue='Action_Priority' and legend=False to resolve the FutureWarning
ax = sns.countplot(
    y='Action_Priority',
    data=strategy_df,
    order=order,
    palette='Reds_r',
    hue='Action_Priority',
    legend=False
)

plt.title('AI-Driven Retention Strategy: Employee Risk Distribution', fontsize=15)
plt.xlabel('Number of Employees')
plt.ylabel('Action Category')

# Add counts to the bars for clarity
for p in ax.patches:
    width = p.get_width()
    if width > 0: # Only label bars that have data
        ax.annotate(f'{int(width)}',
                    (width + 5, p.get_y() + 0.5),
                    fontsize=12, color='black', weight='bold')

plt.tight_layout()
plt.savefig('hr_strategy_tiers_fixed.png')
plt.show()

# --- 4. EXPORT THE PRIORITY LIST ---
priority_list = strategy_df.sort_values(by='Risk_Score_%', ascending=False)
priority_list.to_csv('hr_priority_action_list.csv', index=False)

print("--- STRATEGIC SUMMARY ---")
print(strategy_df['Action_Priority'].value_counts())
print(f"\nClean file saved: 'hr_priority_action_list.csv'")

from sklearn.metrics import roc_curve, auc

# 1. GET PREDICTED PROBABILITIES
# We need the continuous probability scores rather than just the 0/1 predictions
y_probs = final_model.predict_proba(X)[:, 1]

# 2. CALCULATE ROC AND AUC
fpr, tpr, thresholds = roc_curve(y, y_probs)
roc_auc = auc(fpr, tpr)

# 3. PLOT THE ROC CURVE
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # Baseline (Random Guess)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (Stable Employees predicted as Changers)')
plt.ylabel('True Positive Rate (Changers correctly identified)')
plt.title('Model Performance: Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.savefig('roc_curve.png')
plt.show()

print(f"The model's AUC Score is: {roc_auc:.4f}")

import joblib

# 1. SAVE THE TRAINED MODEL
# We use joblib to 'freeze' the model into a file
model_filename = 'retention_model_xgb.pkl'
joblib.dump(final_model, model_filename)

# 2. SAVE THE FEATURE LIST
# This ensures that when we reload the model, we use the columns in the exact same order
model_columns = list(X.columns)
joblib.dump(model_columns, 'model_columns.pkl')

print(f"--- DEPLOYMENT READY ---")
print(f"1. Model saved as: {model_filename}")
print(f"2. Features saved as: model_columns.pkl")
print("\nYou can now move these files to a server or cloud environment to make real-time predictions!")

# --- EXAMPLE: HOW TO LOAD IT LATER ---
# loaded_model = joblib.load('retention_model_xgb.pkl')
# prediction = loaded_model.predict(new_data)

